<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Send comments to: Tony T (tthrall)">

<title>7&nbsp; Dimension Reduction – EDA for Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./text-analysis.html" rel="next">
<link href="./la-intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-133c58409b7dc85f2ab3edd4502409fb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="site_libs/plotly-binding-4.11.0/plotly.js"></script>

<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>

<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>

<link href="site_libs/crosstalk-1.2.2/css/crosstalk.min.css" rel="stylesheet">

<script src="site_libs/crosstalk-1.2.2/js/crosstalk.min.js"></script>

<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">

<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./la-intro.html">Linear Algebra</a></li><li class="breadcrumb-item"><a href="./reduce-dim.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimension Reduction</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">EDA for Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tthrall/eda4ml/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Exploratory Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conditioning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Conditional Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Clustering: EDA in Higher Dimensions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Statistical Simulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./study-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sampling and Study Design</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Linear Algebra</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./la-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reduce-dim.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimension Reduction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Text Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Text Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dirichlet-dstn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Dirichlet Distribution</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./latent-dirichlet-alloc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Latent Dirichlet Allocation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Time Series Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ts-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Time Series Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ts-forecast.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Time Series Forecasting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ts-fourier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Time Series Spectrum Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Graph Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./graph-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Graph Theory for Machine Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./em-algorithm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">EM: the Expectation-Maximization Algorithm</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-dim-r-data-examples" id="toc-sec-dim-r-data-examples" class="nav-link active" data-scroll-target="#sec-dim-r-data-examples"><span class="header-section-number">7.1</span> Data Examples</a>
  <ul class="collapse">
  <li><a href="#us-arrests" id="toc-us-arrests" class="nav-link" data-scroll-target="#us-arrests"><span class="header-section-number">7.1.1</span> US Arrests</a></li>
  <li><a href="#dry-beans" id="toc-dry-beans" class="nav-link" data-scroll-target="#dry-beans"><span class="header-section-number">7.1.2</span> Dry Beans</a></li>
  <li><a href="#wine-quality" id="toc-wine-quality" class="nav-link" data-scroll-target="#wine-quality"><span class="header-section-number">7.1.3</span> Wine Quality</a></li>
  <li><a href="#cancer-genomics-nci60" id="toc-cancer-genomics-nci60" class="nav-link" data-scroll-target="#cancer-genomics-nci60"><span class="header-section-number">7.1.4</span> Cancer Genomics (NCI60)</a></li>
  </ul></li>
  <li><a href="#sec-dim-r-curse" id="toc-sec-dim-r-curse" class="nav-link" data-scroll-target="#sec-dim-r-curse"><span class="header-section-number">7.2</span> Dimensionality: Curse and Blessing</a></li>
  <li><a href="#sec-dim-r-pca" id="toc-sec-dim-r-pca" class="nav-link" data-scroll-target="#sec-dim-r-pca"><span class="header-section-number">7.3</span> Principal Component Analysis</a>
  <ul class="collapse">
  <li><a href="#d-example" id="toc-d-example" class="nav-link" data-scroll-target="#d-example"><span class="header-section-number">7.3.1</span> 2D Example</a></li>
  </ul></li>
  <li><a href="#sec-dim-r-supervised" id="toc-sec-dim-r-supervised" class="nav-link" data-scroll-target="#sec-dim-r-supervised"><span class="header-section-number">7.4</span> Supervised Dimension Reduction</a></li>
  <li><a href="#sec-dim-r-computation" id="toc-sec-dim-r-computation" class="nav-link" data-scroll-target="#sec-dim-r-computation"><span class="header-section-number">7.5</span> Computational Considerations</a></li>
  <li><a href="#sec-dim-r-choose-method" id="toc-sec-dim-r-choose-method" class="nav-link" data-scroll-target="#sec-dim-r-choose-method"><span class="header-section-number">7.6</span> Choosing and Evaluating Methods</a></li>
  <li><a href="#sec-dim-r-other-methods" id="toc-sec-dim-r-other-methods" class="nav-link" data-scroll-target="#sec-dim-r-other-methods"><span class="header-section-number">7.7</span> Other Methods</a></li>
  <li><a href="#sec-dim-r-summary" id="toc-sec-dim-r-summary" class="nav-link" data-scroll-target="#sec-dim-r-summary"><span class="header-section-number">7.8</span> Summary</a></li>
  <li><a href="#sec-dim-r-exercises" id="toc-sec-dim-r-exercises" class="nav-link" data-scroll-target="#sec-dim-r-exercises"><span class="header-section-number">7.9</span> Exercises</a></li>
  <li><a href="#appendix-a-matrix-decompositions-and-pca" id="toc-appendix-a-matrix-decompositions-and-pca" class="nav-link" data-scroll-target="#appendix-a-matrix-decompositions-and-pca"><span class="header-section-number">7.10</span> Appendix A: Matrix Decompositions and PCA</a>
  <ul class="collapse">
  <li><a href="#preliminaries" id="toc-preliminaries" class="nav-link" data-scroll-target="#preliminaries"><span class="header-section-number">7.10.1</span> Preliminaries</a></li>
  <li><a href="#outline-reconstructing-the-feature-matrix" id="toc-outline-reconstructing-the-feature-matrix" class="nav-link" data-scroll-target="#outline-reconstructing-the-feature-matrix"><span class="header-section-number">7.10.2</span> Outline: reconstructing the feature matrix</a></li>
  <li><a href="#details-reconstructing-the-feature-matrix" id="toc-details-reconstructing-the-feature-matrix" class="nav-link" data-scroll-target="#details-reconstructing-the-feature-matrix"><span class="header-section-number">7.10.3</span> Details: reconstructing the feature matrix</a></li>
  <li><a href="#matrix-decompositions" id="toc-matrix-decompositions" class="nav-link" data-scroll-target="#matrix-decompositions"><span class="header-section-number">7.10.4</span> Matrix decompositions</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/tthrall/eda4ml/edit/main/reduce-dim.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/tthrall/eda4ml/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./la-intro.html">Linear Algebra</a></li><li class="breadcrumb-item"><a href="./reduce-dim.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimension Reduction</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-reduce-dim" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimension Reduction</span></span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Send comments to: Tony T (tthrall) </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">10:14 Tue 11-Nov-2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This chapter addresses the problem of finding and visualizing structure in high-dimensional data. We begin the discussion with example data sets.</p>
<section id="sec-dim-r-data-examples" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="sec-dim-r-data-examples"><span class="header-section-number">7.1</span> Data Examples</h2>
<section id="us-arrests" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="us-arrests"><span class="header-section-number">7.1.1</span> US Arrests</h3>
<p>Data analysis often begins with an exploration, using tables and figures to learn more about the data before formulating specific questions or hypotheses. The exploration becomes more difficult as the dimensions of the data set increase. Here’s an example.</p>
<p><span class="citation" data-cites="McNeil_1977">McNeil (<a href="references.html#ref-McNeil_1977" role="doc-biblioref">1977</a>)</span> reviewed the relationship among violent crime statistics per US state and the percent of the population living in urban areas, variables described in <a href="#tbl-arrests-per-us-state-1973" class="quarto-xref">Table&nbsp;<span>7.1</span></a> below. With just four variables, we can visualize the full data structure (e.g., using a scatter plot matrix as shown in <a href="#fig-arrests-2d-scatter-matrix" class="quarto-xref">Figure&nbsp;<span>7.3</span></a>). However, the initial exploratory data analysis reveals strong correlations among the three crime variables (Murder, Assault, Rape), suggesting that the data may effectively lie in fewer than four dimensions. Dimension reduction techniques can help us identify these underlying patterns, enabling us to (1) visualize state-level crime patterns in 2D or 3D, (2) identify states having similar crime profiles, and (3) understand whether crime variation is driven by one dominant factor or multiple independent factors.</p>
<p><a href="#tbl-stats-per-us-state-1970s" class="quarto-xref">Table&nbsp;<span>7.2</span></a> below describes related state-level statistics from the same period (the 1970s). The data from both tables are available from the core <code>R</code> package <code>datasets</code>.</p>
<div class="cell">
<div id="tbl-arrests-per-us-state-1973" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-arrests-per-us-state-1973-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.1: Arrests per US State (1973)
</figcaption>
<div aria-describedby="tbl-arrests-per-us-state-1973-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<caption>Arrests per US State (1973)</caption>
<thead>
<tr class="header">
<th style="text-align: left;">variable</th>
<th style="text-align: right;">year</th>
<th style="text-align: left;">unit</th>
<th style="text-align: left;">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Assault</td>
<td style="text-align: right;">1973</td>
<td style="text-align: left;">100K</td>
<td style="text-align: left;">assault arrests per 100K population</td>
</tr>
<tr class="even">
<td style="text-align: left;">Rape</td>
<td style="text-align: right;">1973</td>
<td style="text-align: left;">100K</td>
<td style="text-align: left;">rape arrests per 100K population</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Murder</td>
<td style="text-align: right;">1973</td>
<td style="text-align: left;">100K</td>
<td style="text-align: left;">murder arrests per 100K population</td>
</tr>
<tr class="even">
<td style="text-align: left;">UrbanPop</td>
<td style="text-align: right;">1973</td>
<td style="text-align: left;">PCT</td>
<td style="text-align: left;">percent of population in urban areas</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div id="tbl-stats-per-us-state-1970s" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-stats-per-us-state-1970s-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.2: Statistics per US State (1970s)
</figcaption>
<div aria-describedby="tbl-stats-per-us-state-1970s-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<caption>Statistics per US State (1970s)</caption>
<thead>
<tr class="header">
<th style="text-align: left;">variable</th>
<th style="text-align: right;">year</th>
<th style="text-align: left;">unit</th>
<th style="text-align: left;">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">st_abb</td>
<td style="text-align: right;">1963</td>
<td style="text-align: left;">chr</td>
<td style="text-align: left;">2-letter abbreviation of state name</td>
</tr>
<tr class="even">
<td style="text-align: left;">st_nm</td>
<td style="text-align: right;">1959</td>
<td style="text-align: left;">chr</td>
<td style="text-align: left;">state name</td>
</tr>
<tr class="odd">
<td style="text-align: left;">x</td>
<td style="text-align: right;">1959</td>
<td style="text-align: left;">lat-long</td>
<td style="text-align: left;">longitude of state center</td>
</tr>
<tr class="even">
<td style="text-align: left;">y</td>
<td style="text-align: right;">1959</td>
<td style="text-align: left;">lat-long</td>
<td style="text-align: left;">latitude of state center</td>
</tr>
<tr class="odd">
<td style="text-align: left;">division</td>
<td style="text-align: right;">1959</td>
<td style="text-align: left;">fct</td>
<td style="text-align: left;">geo grouping into 9 groups</td>
</tr>
<tr class="even">
<td style="text-align: left;">region</td>
<td style="text-align: right;">1959</td>
<td style="text-align: left;">fct</td>
<td style="text-align: left;">geo grouping into 4 groups</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Population</td>
<td style="text-align: right;">1975</td>
<td style="text-align: left;">1000</td>
<td style="text-align: left;">estimated population</td>
</tr>
<tr class="even">
<td style="text-align: left;">Income</td>
<td style="text-align: right;">1974</td>
<td style="text-align: left;">USD</td>
<td style="text-align: left;">average income</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Illiteracy</td>
<td style="text-align: right;">1970</td>
<td style="text-align: left;">PCT</td>
<td style="text-align: left;">illiterate percent of population</td>
</tr>
<tr class="even">
<td style="text-align: left;">Life Exp</td>
<td style="text-align: right;">1969</td>
<td style="text-align: left;">YR</td>
<td style="text-align: left;">life expetency in years</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Murder_76</td>
<td style="text-align: right;">1976</td>
<td style="text-align: left;">100K</td>
<td style="text-align: left;">murder rate per 100K population</td>
</tr>
<tr class="even">
<td style="text-align: left;">HS Grad</td>
<td style="text-align: right;">1970</td>
<td style="text-align: left;">PCT</td>
<td style="text-align: left;">percent high-school graduates</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Frost</td>
<td style="text-align: right;">1960</td>
<td style="text-align: left;">DAY</td>
<td style="text-align: left;">avg number of days below freezing</td>
</tr>
<tr class="even">
<td style="text-align: left;">Area</td>
<td style="text-align: right;">1959</td>
<td style="text-align: left;">mi^2</td>
<td style="text-align: left;">land area in square miles</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p><a href="#fig-arrests-violin" class="quarto-xref">Figure&nbsp;<span>7.1</span></a> below shows the distribution across the 50 states of each type of violent crime. Rates are calcuated as arrests per 100,000 population. The figure shows these rates on a <span class="math inline">\(\log_{10}\)</span> scale, since assault arrests are many times more common than rape or murder arrests.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-arrests-violin" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-arrests-violin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="reduce-dim_files/figure-html/fig-arrests-violin-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-arrests-violin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Violent Crime Rates per US State (1973)
</figcaption>
</figure>
</div>
</div>
</div>
<p>The figure above gives a view of three data variables, that is, three columns of the data matrix. <a href="#fig-arrests-3d-scatter" class="quarto-xref">Figure&nbsp;<span>7.2</span></a> below, a 3D scatterplot, gives a complementary view of each of the 50 states as a point whose coordinates are the respective arrest rates for assault, rape, and murder, with each point colored by the value of <code>UrbanPop</code> the percentage of the state’s population living in an urban area. Since individual states correspond to the rows of the data matrix, this figure is a row-based perspective on the data matrix.</p>
<div class="cell">
<div id="fig-arrests-3d-scatter" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-arrests-3d-scatter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="plotly html-widget html-fill-item" id="htmlwidget-434545c9be6ed594382a" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-434545c9be6ed594382a">{"x":{"visdat":{"9a801008ea":["function () ","plotlyVisDat"]},"cur_data":"9a801008ea","attrs":{"9a801008ea":{"x":{},"y":{},"z":{},"mode":"markers","text":{},"marker":{"size":5,"color":{},"colorscale":"Viridis","showscale":true,"colorbar":{"title":"UrbanPop"}},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Assault"},"yaxis":{"title":"Rape"},"zaxis":{"title":"Murder"}},"title":"Violent Crime Rates in each US State (1973)","hovermode":"closest","showlegend":false},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[236,263,294,190,276,204,110,238,335,211,46,120,249,113,56,115,109,249,83,300,149,255,72,259,178,109,102,252,57,159,285,254,337,45,120,151,159,106,174,279,86,188,201,120,48,156,145,81,53,161],"y":[21.199999999999999,44.5,31,19.5,40.600000000000001,38.700000000000003,11.1,15.800000000000001,31.899999999999999,25.800000000000001,20.199999999999999,14.199999999999999,24,21,11.300000000000001,18,16.300000000000001,22.199999999999999,7.7999999999999998,27.800000000000001,16.300000000000001,35.100000000000001,14.9,17.100000000000001,28.199999999999999,16.399999999999999,16.5,46,9.5,18.800000000000001,32.100000000000001,26.100000000000001,16.100000000000001,7.2999999999999998,21.399999999999999,20,29.300000000000001,14.9,8.3000000000000007,22.5,12.800000000000001,26.899999999999999,25.5,22.899999999999999,11.199999999999999,20.699999999999999,26.199999999999999,9.3000000000000007,10.800000000000001,15.6],"z":[13.199999999999999,10,8.0999999999999996,8.8000000000000007,9,7.9000000000000004,3.2999999999999998,5.9000000000000004,15.4,17.399999999999999,5.2999999999999998,2.6000000000000001,10.4,7.2000000000000002,2.2000000000000002,6,9.6999999999999993,15.4,2.1000000000000001,11.300000000000001,4.4000000000000004,12.1,2.7000000000000002,16.100000000000001,9,6,4.2999999999999998,12.199999999999999,2.1000000000000001,7.4000000000000004,11.4,11.1,13,0.80000000000000004,7.2999999999999998,6.5999999999999996,4.9000000000000004,6.2999999999999998,3.3999999999999999,14.4,3.7999999999999998,13.199999999999999,12.699999999999999,3.2000000000000002,2.2000000000000002,8.5,4,5.7000000000000002,2.6000000000000001,6.7999999999999998],"mode":"markers","text":["AL","AK","AZ","AR","CA","CO","CT","DE","FL","GA","HI","ID","IL","IN","IA","KS","KY","LA","ME","MD","MA","MI","MN","MS","MO","MT","NE","NV","NH","NJ","NM","NY","NC","ND","OH","OK","OR","PA","RI","SC","SD","TN","TX","UT","VT","VA","WA","WV","WI","WY"],"marker":{"color":[58,48,80,50,91,78.5,77,72,80.5,60,83,54,83,65,57,66,52,66,51,76.599999999999994,85,74,66,44.5,70,53,61.5,81,56,89,70,86,45,44,75,68,67,71.5,87,48,45,59,80,80,32,63,73,39,66,60.5],"size":5,"colorscale":"Viridis","showscale":true,"colorbar":{"title":"UrbanPop"},"line":{"color":"rgba(31,119,180,1)"}},"type":"scatter3d","error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-arrests-3d-scatter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Violent Crime Rates in each US State (1973)
</figcaption>
</figure>
</div>
</div>
<p><a href="#fig-arrests-2d-scatter-matrix" class="quarto-xref">Figure&nbsp;<span>7.3</span></a> below exemplifies a matrix of 2D scatter plots, a display method that accommodates more than 3 variables (but not many more, practically speaking).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-arrests-2d-scatter-matrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-arrests-2d-scatter-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="reduce-dim_files/figure-html/fig-arrests-2d-scatter-matrix-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-arrests-2d-scatter-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: Arrests Variables: Relationships and Correlations
</figcaption>
</figure>
</div>
</div>
</div>
<p>This figure provides both column-based and row-based views of the data matrix, with the scatter diagrams for each pair of variables providing the row-based perspective.</p>
</section>
<section id="dry-beans" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="dry-beans"><span class="header-section-number">7.1.2</span> Dry Beans</h3>
<p><span class="citation" data-cites="Koklu_Ozkan_2020_multiclass">Koklu and Ozkan (<a href="references.html#ref-Koklu_Ozkan_2020_multiclass" role="doc-biblioref">2020</a>)</span> published a dataset of visual characteristics of dried beans “… in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera.” The resulting dataset contains 16 morphological features extracted from each bean image, including measures of area, perimeter, compactness, length, width, and various shape factors.</p>
<p>The classification goal is to predict bean variety from these morphological measurements. Successful classification could have many applications, e.g., to improve sorting systems in agricultural processing. However, many of these 16 features are inherently redundant: for example, area and perimeter are strongly correlated, as are various length and width measurements. Dimension reduction can reveal whether bean varieties differ primarily in size, shape, or both, and whether a smaller subset of derived features might achieve comparable classification accuracy with greater interpretability and computational efficiency.</p>
<p>The data are available <code>R</code> package <code>beans</code>, containing a data matrix (tibble, more precisely) of dimension <span class="math inline">\(13611 \times 17\)</span>. The last column of the data matrix is response variable <code>class</code> that assigns one of seven types of bean to each bean-image. The remaining 16 columns of the data matrix are morphological measurements (of shape and size).</p>
<p><span class="citation" data-cites="Kuhn_Silge_tmwr">Kuhn and Silge (<a href="references.html#ref-Kuhn_Silge_tmwr" role="doc-biblioref">2022</a>)</span> develop and evaluate different classification models for these data. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> They begin by examining the correlation coefficients for each pair of the 16 feature vectors. <a href="#fig-beans-corrplot" class="quarto-xref">Figure&nbsp;<span>7.4</span></a> follows their example.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-beans-corrplot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-beans-corrplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="reduce-dim_files/figure-html/fig-beans-corrplot-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beans-corrplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: beans: correlation among features
</figcaption>
</figure>
</div>
</div>
</div>
<p>In this figure, the absolute value of each correlation coefficient is represented by the narrowness of the drawn ellipse and the depth of its color. The sign of the correlation coefficient is represented by both the color and direction of the ellipse.</p>
<p>These size and shape features measure similar concepts. Consequently, several pairs of feature vectors are highly correlated, <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> which offers the possibility of transforming the 16 original features into a smaller set without sacrificing classification power.</p>
</section>
<section id="wine-quality" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="wine-quality"><span class="header-section-number">7.1.3</span> Wine Quality</h3>
<p><span class="citation" data-cites="Cortez_2009_ModelingWP">P. Cortez et al. (<a href="references.html#ref-Cortez_2009_ModelingWP" role="doc-biblioref">2009</a>)</span> model wine preference as a function of 12 physicochemical properties of wine, which are listed in <a href="#tbl-wq-var-dscr" class="quarto-xref">Table&nbsp;<span>7.3</span></a>. The <code>quality</code> score is the median of three expert tastings. The data consist of 6497 wines, 1599 red and 4898 white. <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>The modeling goal is to understand the chemical properties influencing wine quality ratings and to predict quality from objective laboratory measurements. Apart from wine color (red or white), the remaining 11 physicochemical features include related measurements, e.g., pH, fixed acidity, and citric acid are chemically interrelated, as are free and total sulfur dioxide. Dimension reduction can help us: (1) visualize the chemical space that wines occupy in 2D or 3D, (2) identify whether wine quality varies along a small number of chemical gradients (e.g., acidity vs.&nbsp;alcohol content), (3) understand the chemical differences between red and white wines, and (4) determine whether a smaller set of derived features might predict quality as well as the full set of measurements.</p>
<div class="cell">
<div id="tbl-wq-var-dscr" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-wq-var-dscr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.3: Wine: physicochemical properties
</figcaption>
<div aria-describedby="tbl-wq-var-dscr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<caption>Wine: physicochemical properties</caption>
<thead>
<tr class="header">
<th style="text-align: left;">variable</th>
<th style="text-align: left;">unit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">fixed acidity</td>
<td style="text-align: left;">g(tartaric acid)/dm3</td>
</tr>
<tr class="even">
<td style="text-align: left;">volatile acidity</td>
<td style="text-align: left;">g(acetic acid)/dm3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">citric acid</td>
<td style="text-align: left;">g/dm3</td>
</tr>
<tr class="even">
<td style="text-align: left;">residual sugar</td>
<td style="text-align: left;">g/dm3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">chlorides</td>
<td style="text-align: left;">g(sodium chloride)/dm3</td>
</tr>
<tr class="even">
<td style="text-align: left;">free sulfur dioxide</td>
<td style="text-align: left;">mg/dm3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">total sulfur dioxide</td>
<td style="text-align: left;">mg/dm3</td>
</tr>
<tr class="even">
<td style="text-align: left;">density</td>
<td style="text-align: left;">g/cm3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pH</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">sulphates</td>
<td style="text-align: left;">g(potassium sulphate)/dm3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">alcohol</td>
<td style="text-align: left;">% volume</td>
</tr>
<tr class="even">
<td style="text-align: left;">quality</td>
<td style="text-align: left;">0:10</td>
</tr>
<tr class="odd">
<td style="text-align: left;">color</td>
<td style="text-align: left;">{red, white}</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Correlations among the 11 numeric features are shown in <a href="#fig-rw-wq-corrplot" class="quarto-xref">Figure&nbsp;<span>7.5</span></a> below for red and white wines, respectively.</p>
<div id="fig-rw-wq-corrplot" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rw-wq-corrplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-rw-wq-corrplot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-rw-wq-corrplot-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-rw-wq-corrplot-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="reduce-dim_files/figure-html/fig-rw-wq-corrplot-1.png" class="img-fluid figure-img" data-ref-parent="fig-rw-wq-corrplot" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-rw-wq-corrplot-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Red wines
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-rw-wq-corrplot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-rw-wq-corrplot-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-rw-wq-corrplot-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="reduce-dim_files/figure-html/fig-rw-wq-corrplot-2.png" class="img-fluid figure-img" data-ref-parent="fig-rw-wq-corrplot" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-rw-wq-corrplot-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) White wines
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rw-wq-corrplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Wine: correlation among numeric features
</figcaption>
</figure>
</div>
<p>These figures reveal some substantial correlations, with distinct patterns per wine color.</p>
<p><a href="#tbl-rw-quality-corr" class="quarto-xref">Table&nbsp;<span>7.4</span></a> below shows feature-quality correlations for red and white wines, respectively.</p>
<div class="cell">
<div id="tbl-rw-quality-corr" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-rw-quality-corr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.4: Feature-quality correleations among (red, white) wines
</figcaption>
<div aria-describedby="tbl-rw-quality-corr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<caption>Feature-quality correleations</caption>
<thead>
<tr class="header">
<th style="text-align: left;">feature</th>
<th style="text-align: right;">q_red</th>
<th style="text-align: right;">q_white</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">fixed acidity</td>
<td style="text-align: right;">0.12</td>
<td style="text-align: right;">-0.11</td>
</tr>
<tr class="even">
<td style="text-align: left;">volatile acidity</td>
<td style="text-align: right;">-0.39</td>
<td style="text-align: right;">-0.19</td>
</tr>
<tr class="odd">
<td style="text-align: left;">citric acid</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">-0.01</td>
</tr>
<tr class="even">
<td style="text-align: left;">residual sugar</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">-0.10</td>
</tr>
<tr class="odd">
<td style="text-align: left;">chlorides</td>
<td style="text-align: right;">-0.13</td>
<td style="text-align: right;">-0.21</td>
</tr>
<tr class="even">
<td style="text-align: left;">free sulfur dioxide</td>
<td style="text-align: right;">-0.05</td>
<td style="text-align: right;">0.01</td>
</tr>
<tr class="odd">
<td style="text-align: left;">total sulfur dioxide</td>
<td style="text-align: right;">-0.19</td>
<td style="text-align: right;">-0.17</td>
</tr>
<tr class="even">
<td style="text-align: left;">density</td>
<td style="text-align: right;">-0.17</td>
<td style="text-align: right;">-0.31</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pH</td>
<td style="text-align: right;">-0.06</td>
<td style="text-align: right;">0.10</td>
</tr>
<tr class="even">
<td style="text-align: left;">sulphates</td>
<td style="text-align: right;">0.25</td>
<td style="text-align: right;">0.05</td>
</tr>
<tr class="odd">
<td style="text-align: left;">alcohol</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0.44</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>We see that alcohol volume is a prominent indicator of quality for both red and white wines. On the other hand, citric acid and sulphates are strongly correlated with the quality of red wine, but not white.</p>
<p>As demonstrated by <span class="citation" data-cites="Cortez_2009_ModelingWP">P. Cortez et al. (<a href="references.html#ref-Cortez_2009_ModelingWP" role="doc-biblioref">2009</a>)</span>, these data patterns offer the possibility of developing a smaller set of features as predictors of wine quality.</p>
</section>
<section id="cancer-genomics-nci60" class="level3" data-number="7.1.4">
<h3 data-number="7.1.4" class="anchored" data-anchor-id="cancer-genomics-nci60"><span class="header-section-number">7.1.4</span> Cancer Genomics (NCI60)</h3>
<p>The NCI60 data <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> consists of gene expression measurements from 64 cancer cell lines. For each cell line, expression levels were measured for 6830 genes using microarray technology. The cell lines represent 14 different cancer types, including leukemia, melanoma, and cancers of the colon, breast, ovary, lung, and central nervous system. This data set is a canonical example of a high-dimensional data matrix where the number of features <span class="math inline">\((d)\)</span> greatly exceeds the number <span class="math inline">\(n\)</span> of data cases: <span class="math inline">\(d \gg n\)</span>.</p>
<p>The data set is part of the NCI-60 panel and associated datasets, which are maintained by the Frederick National Laboratory for Cancer Research (FNLCR) and the National Cancer Institute’s (NCI) Developmental Therapeutics Program (DTP). The data serve as a publicly available platform for the global cancer research community to study tumor biology, evaluate new bioinformatics approaches, and select appropriate cell models for specific research questions.</p>
<p>These data present challenges that require dimension reduction, that is, the transformation of the set of 6830 genomic features into a smaller set that capture the dominant patterns of variation. We proceed to describe such challenges.</p>
</section>
</section>
<section id="sec-dim-r-curse" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-dim-r-curse"><span class="header-section-number">7.2</span> Dimensionality: Curse and Blessing</h2>
<p>As just noted, the NCI60 data set, with <span class="math inline">\(d =\)</span> 6830 and <span class="math inline">\(n =\)</span> 64, presents challenges that make dimension reduction essential. Several issues arise with any “wide” data set in which <span class="math inline">\(d \gg n\)</span>, and include the following.</p>
<ul>
<li><p><em>Visualization</em>: We cannot plot points in <span class="math inline">\(d\)</span> dimensions to explore patterns or detect outliers.</p></li>
<li><p><em>Over-fitting</em>: With <span class="math inline">\(d \gg n\)</span>, infinitely many coefficient vectors <span class="math inline">\(\beta_\bullet\)</span> produce identical predictions that replicate the response variable within the training data. This makes model selection impossible without regularization.</p></li>
<li><p><em>Computation</em>: Storing and manipulating a <span class="math inline">\(d \times d\)</span> covariance matrix becomes prohibitively expensive.</p></li>
</ul>
<p>In 1957 Richard Bellman characterized such challenges as “the curse of dimensionality”. <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p><span class="citation" data-cites="Donoho_2000_High_Dimensional_Data_Analysis">Donoho (<a href="references.html#ref-Donoho_2000_High_Dimensional_Data_Analysis" role="doc-biblioref">2000</a>)</span> points out that: (1) many established statistical methods assume <span class="math inline">\(d &lt; n\)</span>; and (2) we can expect <span class="math inline">\(d \gg n\)</span> to occur more and more often as data-collection is increasingly automated to retrieve all potentially useful details for subsequent screening.</p>
<p>In addition, <span class="citation" data-cites="wiki_curse_dimensionality"><span>“Curse of Dimensionality | Wikipedia”</span> (<a href="references.html#ref-wiki_curse_dimensionality" role="doc-biblioref">2025</a>)</span> notes that our geometric intuition is grounded in <span class="math inline">\(d \le 3\)</span> and is overturned as <span class="math inline">\(d\)</span> increases. To illustrate, consider a unit hypercube <span class="math inline">\([0,1]^d\)</span> containing the largest possible inscribed ball. The ratio <span class="math inline">\(r(d)\)</span> of their volumes shrinks dramatically: <span class="math inline">\(r(3) \approx 0.52\)</span>, <span class="math inline">\(r(10) \approx 0.0025\)</span>, and <span class="math inline">\(r(100) \approx 2 \times 10^{-70}\)</span>. In high dimensions, the preponderance of randomly generated points within the cube land far from the center!</p>
<p>Yet <span class="citation" data-cites="Donoho_2000_High_Dimensional_Data_Analysis">Donoho (<a href="references.html#ref-Donoho_2000_High_Dimensional_Data_Analysis" role="doc-biblioref">2000</a>)</span> also sees opportunities. While randomly generated data in high dimensions behaves pathologically, actual data tend to be more coherent. Consider the example data sets:</p>
<ul>
<li><em>US Arrests</em>: The three crime variables (assault, rape, murder) are highly correlated; they don’t independently span 3D space (<a href="#fig-arrests-3d-scatter" class="quarto-xref">Figure&nbsp;<span>7.2</span></a>).</li>
<li><em>Dry_Beans</em>: The 16 shape measurements aren’t independent; they reflect underlying bean geometry.<br>
</li>
<li><em>Wine quality</em>: The 11 chemical properties are constrained by fermentation chemistry.</li>
<li><em>NCI60</em>: The 6,830 genes participate in shared biological pathways.</li>
</ul>
<p>In each case, the data likely occupies a much lower-dimensional structure within the high-dimensional feature space. If we can identify this structure, dimension reduction may actually <em>improve</em> modeling by revealing the true degrees of freedom in the data.</p>
<p>The remainder of this chapter develops methods that exploit such opportunities. We begin with Principal Component Analysis (<a href="#sec-dim-r-pca" class="quarto-xref"><span>Section 7.3</span></a>), which finds low-dimensional approximations to high-dimensional data through eigen-decomposition. We then explore how supervision (<a href="#sec-dim-r-supervised" class="quarto-xref"><span>Section 7.4</span></a>) can guide dimension reduction when prediction is the goal. Finally, we examine computational strategies (<a href="#sec-dim-r-computation" class="quarto-xref"><span>Section 7.5</span></a>) for extreme cases like NCI60 where <span class="math inline">\(d \gg n\)</span>.</p>
</section>
<section id="sec-dim-r-pca" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="sec-dim-r-pca"><span class="header-section-number">7.3</span> Principal Component Analysis</h2>
<p>Recall the US Arrests dataset with four crime-related variables. Can we represent these 50 states in fewer than four dimensions while preserving most of the information? Principal Component Analysis (PCA) answers this by finding new variables, linear combinations of the original features, that capture maximum variance.</p>
<section id="d-example" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="d-example"><span class="header-section-number">7.3.1</span> 2D Example</h3>
<p>To develop some geometric intuition we begin with a 2D example. <a href="#fig-fs-pca" class="quarto-xref">Figure&nbsp;<span>7.6</span></a> below illustrates PCA for (father, son) centered heights from the Galton data presented in <a href="la-intro.html" class="quarto-xref"><span>Chapter 6</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-fs-pca" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fs-pca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="reduce-dim_files/figure-html/fig-fs-pca-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fs-pca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.6: Principal Components: (father, son) centered heights
</figcaption>
</figure>
</div>
</div>
</div>
<p>The figure represents two principal components, <span class="math inline">\((c_1, c_2)\)</span>, as respective orange and purple lines, which are perpendicular to one another.</p>
<p>The orange line <span class="math inline">\((c_1)\)</span> points in the direction where the data varies most. Projecting points onto this line captures the maximum possible variance in a single dimension. The purple line <span class="math inline">\((c_2)\)</span> is perpendicular to <span class="math inline">\(c_1\)</span> and captures the maximum remaining variance. Together, they form a rotated coordinate system that aligns with the data’s natural variation.</p>
</section>
</section>
<section id="sec-dim-r-supervised" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="sec-dim-r-supervised"><span class="header-section-number">7.4</span> Supervised Dimension Reduction</h2>
</section>
<section id="sec-dim-r-computation" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="sec-dim-r-computation"><span class="header-section-number">7.5</span> Computational Considerations</h2>
</section>
<section id="sec-dim-r-choose-method" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="sec-dim-r-choose-method"><span class="header-section-number">7.6</span> Choosing and Evaluating Methods</h2>
</section>
<section id="sec-dim-r-other-methods" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="sec-dim-r-other-methods"><span class="header-section-number">7.7</span> Other Methods</h2>
</section>
<section id="sec-dim-r-summary" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="sec-dim-r-summary"><span class="header-section-number">7.8</span> Summary</h2>
</section>
<section id="sec-dim-r-exercises" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="sec-dim-r-exercises"><span class="header-section-number">7.9</span> Exercises</h2>
</section>
<section id="appendix-a-matrix-decompositions-and-pca" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="appendix-a-matrix-decompositions-and-pca"><span class="header-section-number">7.10</span> Appendix A: Matrix Decompositions and PCA</h2>
<p>To define principal components we will describe a step-wise reconstruction of the <span class="math inline">\(n \times d\)</span> feature matrix <span class="math inline">\(X_{\bullet, \bullet}\)</span>.</p>
<section id="preliminaries" class="level3" data-number="7.10.1">
<h3 data-number="7.10.1" class="anchored" data-anchor-id="preliminaries"><span class="header-section-number">7.10.1</span> Preliminaries</h3>
<p>First, to simplify notation, we assume <span class="math inline">\(X_{\bullet, \bullet}\)</span> to have already been centered: for each column of the original feature matrix the average value of the column elements has been calculated and subtracted. Therefore the average (or equivalently the sum) of each column of <span class="math inline">\(X_{\bullet, \bullet}\)</span> equals zero.</p>
<p><span id="eq-X-ctr-cols"><span class="math display">\[
\begin{align}
  X_{\bullet, \bullet} &amp;= (x_{\bullet, 1}, \ldots, x_{\bullet, d}) \\ \\
  &amp; \text{with} \\ \\
  1_\bullet^\top \; x_{\bullet, k} &amp;= \sum_{i = 1}^n x_{i, k} = 0 \\ \\
  &amp;\text{for } k \in \{ 1, \ldots, d \} \\ \\
  &amp; \text{so that} \\ \\
  1_\bullet^\top \; X_{\bullet, \bullet} &amp;= 0_\bullet \in \mathbb{R}^d
\end{align}
\qquad(7.1)\]</span></span></p>
<p>As a consequence, the <span class="math inline">\(d \times d\)</span> matrix <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span> is a multiple of the sample covariance matrix among features.</p>
<p><span id="eq-cov-X-mat"><span class="math display">\[
\begin{align}
  cov \left ( X_{\bullet, \bullet} \right )
  &amp;= \frac{1}{n - 1}
  \left (
  X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
  \right )
\end{align}
\qquad(7.2)\]</span></span></p>
<p>In particular, the variance of each feature vector is proportional to its squared norm.</p>
<p><span id="eq-feature-variance-equals-norm2"><span class="math display">\[
\begin{align}
  var( x_{\bullet, k} )
  &amp;= \frac{1}{n - 1}
  \lVert
    x_{\bullet, k}
  \rVert^2
\end{align}
\qquad(7.3)\]</span></span></p>
<p>Although matrix <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span> is a square matrix having dimensions <span class="math inline">\(d \times d\)</span>, its <em>rank</em> may be less than <span class="math inline">\(d\)</span>. Let <span class="math inline">\(r = rank \left ( X_{\bullet, \bullet} \right )\)</span>. Then <span class="math inline">\(r\)</span> is also the rank of <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span>. It is the dimension of the subspace of <span class="math inline">\(\mathbb{R}^d\)</span> spanned by the rows of <span class="math inline">\(X_{\bullet, \bullet}\)</span>, as well as the dimension of the subspace of <span class="math inline">\(\mathbb{R}^n\)</span> spanned by the columns of <span class="math inline">\(X_{\bullet, \bullet}\)</span>. Consequently <span class="math inline">\(r \le \min(n, d)\)</span>.</p>
<p>Our construction of principal components also relies on the notion of an orthogonal projection <span class="math inline">\(P\)</span> from <span class="math inline">\(\mathbb{R}^d\)</span> to some subspace of <span class="math inline">\(\mathbb{R}^d\)</span>. Recall that <span class="math inline">\(P\)</span> is an orthogonal projection if and only if: it is idempotent <span class="math inline">\((P^2 = P)\)</span>; and symmetric <span class="math inline">\((P^\top = P)\)</span>. Also, if <span class="math inline">\(P\)</span> is an orthogonal projection then so is its complement <span class="math inline">\(\mathcal{I} - P\)</span>.</p>
<p>The simplest example is the <span class="math inline">\(d \times d\)</span> matrix <span class="math inline">\(v_\bullet \; v_\bullet^\top\)</span>, where <span class="math inline">\(v_\bullet \in \mathbb{R}^d\)</span> is a unit vector (a vector of unit norm). This sends <span class="math inline">\(x_\bullet \in \mathbb{R}^d\)</span> to a scalar multiple of <span class="math inline">\(v_\bullet\)</span>, namely <span class="math inline">\(\left &lt; x_\bullet, v_\bullet \right &gt; v_\bullet\)</span>. <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>To any projection <span class="math inline">\(P\)</span> defined on <span class="math inline">\(\mathbb{R}^d\)</span> we apply the following loss function <span class="math inline">\(\mathcal{L} (\cdot)\)</span> in order to measure how well <span class="math inline">\(P\)</span> reproduces the rows of the feature matrix <span class="math inline">\(X_{\bullet, \bullet}\)</span>. <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p><span id="eq-row-projection-squared-error"><span class="math display">\[
\begin{align}
  \mathcal{L} \left ( P \right )
  &amp;=
    \sum_{i = 1}^n
    \; \left \lVert
      x_{i, \bullet} \; - \; P \; x_{i, \bullet}
    \right \rVert^2 \\
  &amp;=
    \sum_{i = 1}^n
    \; \left \lVert
    \left (
      \mathcal{I} \; - \; P
    \right )
      \; x_{i, \bullet}
    \right \rVert^2 \\
  &amp;=
    \sum_{i = 1}^n
      \left &lt;
        x_{i, \bullet}, \;
        \left (
          \mathcal{I} \; - \; P
        \right ) \;
        x_{i, \bullet}
      \right &gt; \\
  &amp;=
    \sum_{i = 1}^n
      \left (
        \left &lt;
          x_{i, \bullet}, \;
          x_{i, \bullet}
        \right &gt; \; - \;
        \left &lt;
          x_{i, \bullet}, \;
          P \;
          x_{i, \bullet}
        \right &gt;
      \right ) \\
  &amp;=
    \sum_{i = 1}^n
      \left (
        \left &lt;
          x_{i, \bullet}, \;
          x_{i, \bullet}
        \right &gt; \; - \;
        \left &lt;
          P \;
          x_{i, \bullet}, \;
          P \;
          x_{i, \bullet}
        \right &gt;
      \right ) \\
  &amp;=
    \sum_{i = 1}^n
      \lVert
        x_{i, \bullet}
      \rVert^2 \; - \;
    \sum_{i = 1}^n
      \lVert
        P \;
        x_{i, \bullet}
      \rVert^2  \\
  &amp;=
    \mathrm{Tr} \left \{
      X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
      \right \} \; - \;
    \sum_{i = 1}^n
      \lVert
        P \;
        x_{i, \bullet}
      \rVert^2 \\ \\
    &amp; \text{subject to the constraint:} \\ \\
    &amp; P \text{ is an orthogonal projection defined on } \mathbb{R}^d
\end{align}
\qquad(7.4)\]</span></span></p>
<p>Thus <span class="math inline">\(\mathcal{L} (P)\)</span> is a sum over row index <span class="math inline">\(i\)</span> of squared residuals in the approximation of <span class="math inline">\(x_{i, \bullet}\)</span> by <span class="math inline">\(P \; x_{i, \bullet}\)</span>.</p>
<p>Now let <span class="math inline">\(\mathcal{P}\)</span> be a set of projections. From <a href="#eq-row-projection-squared-error" class="quarto-xref">Equation&nbsp;<span>7.4</span></a> we see that projection <span class="math inline">\(\hat{P} \in \mathcal{P}\)</span> minimizes <span class="math inline">\(\mathcal{L} (P)\)</span> if and only if it maximizes a corresponding sum of squares:</p>
<p><span id="eq-min-loss-equals-max-quad-form"><span class="math display">\[
\begin{align}
  &amp;  
  \arg \min_{ P \in \mathcal{P} } \;
  \mathcal{L} ( P ) \\
  &amp;=
  \arg \max_{ P \in \mathcal{P} } \;
  \sum_{i = 1}^n
      \lVert
        P \;
        x_{i, \bullet}
      \rVert^2
\end{align}
\qquad(7.5)\]</span></span></p>
<p>This last sum of squares is proportional to the sum across <span class="math inline">\(X_{\bullet, \bullet}\)</span> columns (each of which is centered) of the variance of the projected column elements. Briefly, minimization of loss function <span class="math inline">\(\mathcal{L} (\cdot)\)</span> amounts to maximization of projected column variance.</p>
</section>
<section id="outline-reconstructing-the-feature-matrix" class="level3" data-number="7.10.2">
<h3 data-number="7.10.2" class="anchored" data-anchor-id="outline-reconstructing-the-feature-matrix"><span class="header-section-number">7.10.2</span> Outline: reconstructing the feature matrix</h3>
<p>Here’s an outline of the reconstruction processs. At step <span class="math inline">\(j\)</span> we define vector <span class="math inline">\(v_{\bullet, j} \in \mathbb{R}^d\)</span> that has unit norm and is orthogonal to any vector <span class="math inline">\(v_{\bullet, \eta}\)</span> defined in any previous step. At the end of step <span class="math inline">\(j\)</span> we have accumulated an orthonormal set of vectors <span class="math inline">\((v_{\bullet, 1}, \ldots, v_{\bullet, j})\)</span> that span a <span class="math inline">\(j-\)</span>dimensional subspace, say <span class="math inline">\(\mathcal{R}^{(j)}\)</span>, of <span class="math inline">\(\mathbb{R}^d\)</span>. This orthonormal set defines the following orthogonal projection <span class="math inline">\(P^{(j)}\)</span> from <span class="math inline">\(\mathbb{R}^d\)</span> to <span class="math inline">\(\mathcal{R}^{(j)}\)</span>.</p>
<p><span id="eq-row-supspace-ortho-projection"><span class="math display">\[
\begin{align}
  P^{(j)} \; x_\bullet
  &amp;=
    \sum_{\eta = 1}^j
      \left &lt; x_\bullet, v_{\bullet, \eta} \right &gt;
      \times v_{\bullet, \eta} \\
  &amp;=
    \sum_{\eta = 1}^j
      v_{\bullet, \eta} \times
      \left &lt; v_{\bullet, \eta}, x_\bullet \right &gt;  \\
  &amp;=
    \sum_{\eta = 1}^j
      v_{\bullet, \eta} \; v_{\bullet, \eta}^\top \; x_\bullet
\end{align}
\qquad(7.6)\]</span></span></p>
<p>In other words, <span class="math inline">\(P^{(j)}\)</span> is the sum of orthogonal projections, <span class="math inline">\(v_{\bullet, \eta} \; v_{\bullet, \eta}^\top\)</span>, to 1-dimensional subspaces that are pair-wise orthogonal.</p>
<p>Since we will apply our loss function <span class="math inline">\(\mathcal{L} (P)\)</span> to <span class="math inline">\(P^{(j)}\)</span>, it will be useful to re-express the sum of squares appearing in <a href="#eq-min-loss-equals-max-quad-form" class="quarto-xref">Equation&nbsp;<span>7.5</span></a>. <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p><span id="eq-projection-quad-form-as-sum"><span class="math display">\[
\begin{align}
  &amp;
  \sum_{i = 1}^n
      \lVert
        P \;
        x_{i, \bullet}
      \rVert^2 \\
  &amp;=
  \sum_{i = 1}^n
    \left &lt;
      x_{i, \bullet}, \;
      P^{(j)} \;
      x_{i, \bullet}
    \right &gt; \\
  &amp;=
  \sum_{i = 1}^n
      x_{i, \bullet} \;
      P^{(j)} \;
      x_{i, \bullet}^\top \\
  &amp;=
  \sum_{i = 1}^n
      x_{i, \bullet} \;
      \left (
        \sum_{\eta = 1}^j
            v_{\bullet, \eta} \; v_{\bullet, \eta}^\top \;
      \right )
      x_{i, \bullet}^\top \\
  &amp;=
  \sum_{i = 1}^n
    \sum_{\eta = 1}^j
      x_{i, \bullet} \;
      v_{\bullet, \eta} \;
      v_{\bullet, \eta}^\top \;
      x_{i, \bullet}^\top \\
  &amp;=
  \sum_{\eta = 1}^j
    \sum_{i = 1}^n  \;
      v_{\bullet, \eta}^\top \;
      x_{i, \bullet}^\top
      x_{i, \bullet} \;
      v_{\bullet, \eta} \\
  &amp;=
  \sum_{\eta = 1}^j
    v_{\bullet, \eta}^\top \;
    \left (
    \sum_{i = 1}^n  \;
      x_{i, \bullet}^\top
      x_{i, \bullet} \;
    \right )
    v_{\bullet, \eta} \\
  &amp;=
  \sum_{\eta = 1}^j
    v_{\bullet, \eta}^\top \;
    \left (
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet}
    \right )
    v_{\bullet, \eta}
\end{align}
\qquad(7.7)\]</span></span></p>
<p>As we will see, the maximization of the type of quadratic form appearing in the last sum above is a solved problem.</p>
</section>
<section id="details-reconstructing-the-feature-matrix" class="level3" data-number="7.10.3">
<h3 data-number="7.10.3" class="anchored" data-anchor-id="details-reconstructing-the-feature-matrix"><span class="header-section-number">7.10.3</span> Details: reconstructing the feature matrix</h3>
<p>Here are the distinctive details of the reconstruction process. At step 1 we define vector <span class="math inline">\(v_{\bullet, 1}\)</span> as the unit vector that minimizes <span class="math inline">\(\mathcal{L} (v_\bullet \; v_\bullet^\top)\)</span> among all unit vectors <span class="math inline">\(v_\bullet \in \mathbb{R}^d\)</span>. From <a href="#eq-min-loss-equals-max-quad-form" class="quarto-xref">Equation&nbsp;<span>7.5</span></a> and <a href="#eq-projection-quad-form-as-sum" class="quarto-xref">Equation&nbsp;<span>7.7</span></a> we have:</p>
<p><span id="eq-max-quad-form-step-1"><span class="math display">\[
\begin{align}
  v_{\bullet, 1}
  &amp;=  
  \arg \min_{ \Vert v_\bullet \rVert = 1 } \;
  \mathcal{L} ( v_\bullet \; v_\bullet^\top ) \\
  &amp;=
  \arg \max_{ \Vert v_\bullet \rVert = 1 } \;
  \sum_{i = 1}^n
    \lVert
      v_\bullet \; v_\bullet^\top \;
      x_{i, \bullet}
    \rVert^2 \\
  &amp;=
  \arg \max_{ \Vert v_\bullet \rVert = 1 } \;
  v_\bullet^\top \;
  \left (
    X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
  \right ) \;
  v_\bullet
\end{align}
\qquad(7.8)\]</span></span></p>
<p>The solution to <a href="#eq-max-quad-form-step-1" class="quarto-xref">Equation&nbsp;<span>7.8</span></a> is well known. The maximal value of <span class="math inline">\(v_\bullet^\top \; X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet} \; v_\bullet\)</span> is the largest eigenvalue, say <span class="math inline">\(\sigma_1^2\)</span>, of <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span>. And the vector <span class="math inline">\(v_{\bullet, 1}\)</span> that achieves that maximal value is the eigenvector corresponding to <span class="math inline">\(\sigma_1^2\)</span>.</p>
<p>Having defined <span class="math inline">\(v_{\bullet, 1}\)</span>, we proceed inductively, again with <span class="math inline">\(r\)</span> defined as <span class="math inline">\(r = rank \left ( X_{\bullet, \bullet} \right )\)</span>. Suppose that we have defined an orthonormal set of vectors <span class="math inline">\(v_{\bullet, 1}, \ldots, v_{\bullet, j}\)</span>, where <span class="math inline">\(1 \le j \le r\)</span>. As previously noted, this orthonormal set of vectors spans a <span class="math inline">\(j-\)</span>dimensional <span class="math inline">\(\mathbb{R}^d\)</span> subspace, denoted <span class="math inline">\(\mathcal{R}^{(j)}\)</span>, and also defines an orthogonal projection <span class="math inline">\(P^{(j)}\)</span> from <span class="math inline">\(\mathbb{R}^d\)</span> to <span class="math inline">\(\mathcal{R}^{(j)}\)</span>.</p>
<p>If <span class="math inline">\(j = r\)</span> we terminate the reconstruction. Otherwise we define the next vector, <span class="math inline">\(v_{\bullet, j + 1}\)</span>, as the unit vector that minimizes <span class="math inline">\(\mathcal{L} (Q^{(j + 1)})\)</span>, where <span class="math inline">\(Q^{(j + 1)} = P^{(j)} \; + \; v_{\bullet} \; v_{\bullet}^\top\)</span>.</p>
<p><span id="eq-next-row-projection-error-a"><span class="math display">\[
\begin{align}
  \mathcal{L}
  \left (
    Q^{(j + 1)} (v_{\bullet} \; v_\bullet^\top)
  \right )
  &amp;=
    \sum_{i = 1}^n
    \left \lVert
    \left (
      \mathcal{I} \; - \;
      Q^{(j + 1)} (v_{\bullet} \; v_\bullet^\top) \;
    \right )
    x_{i, \bullet}
    \right \rVert^2 \\ \\
  &amp;\text{where} \\ \\
  Q^{(j + 1)} (v_{\bullet} \; v_{\bullet}^\top) &amp;= P^{(j)} \; + \; v_{\bullet} \; v_{\bullet}^\top \\ \\
  &amp; \text{subject to the constraints: } \\ \\
  &amp; \lVert v_\bullet \rVert = 1 \; \text{ and } \; v_\bullet \perp v_{\bullet, \eta} \; \text{ for } \; \eta \le j
\end{align}
\qquad(7.9)\]</span></span></p>
<p>Note that the constraints on <span class="math inline">\(v_\bullet\)</span> ensure that <span class="math inline">\(Q^{(j + 1)} (v_{\bullet} \; v_{\bullet}^\top)\)</span> is an orthogonal projection. Then, abbreviating and expanding <a href="#eq-next-row-projection-error-a" class="quarto-xref">Equation&nbsp;<span>7.9</span></a>, we have:</p>
<p><span id="eq-next-row-projection-error-b"><span class="math display">\[
\begin{align}
  &amp;
  \mathcal{L}
  \left (
    Q^{(j + 1)} (v_{\bullet} \; v_\bullet^\top)
  \right ) \\
  &amp;=
    \sum_{i = 1}^n
    \left \lVert
    \left (
      \mathcal{I} \; - \;
      Q^{(j + 1)} \;
    \right )
    x_{i, \bullet}
    \right \rVert^2 \\
  &amp;=
    \mathrm{Tr} \left \{
      X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
      \right \} \; - \;
    \sum_{\eta = 1}^j
    v_{\bullet, \eta}^\top \;
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \;
    v_{\bullet, \eta} \; - \;
    v_\bullet^\top \;
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \;
    v_\bullet
\end{align}
\qquad(7.10)\]</span></span></p>
<p>It now follows that</p>
<p><span id="eq-maximize-quad-form-b"><span class="math display">\[
\begin{align}
  v_{\bullet, j + 1}
  &amp;=
  \arg \max \;
  \left \{
    v_\bullet^\top \;
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \;
    v_\bullet
  \right \} \\ \\
  &amp;\text{subject to: } \\ \\
    &amp;\lVert v_\bullet \rVert = 1 \;
    \text{ and } \;
    v_\bullet \perp v_{\bullet, \eta} \; \text{ for } \eta \le j
\end{align}
\qquad(7.11)\]</span></span></p>
<p>Again, this problem of constrained maximization of a quadratic form is well known. The maximum value is <span class="math inline">\(\sigma_{j + 1}^2\)</span>, the eigenvalue of <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span> of index <span class="math inline">\(j + 1\)</span> in descending order. The vector <span class="math inline">\(v_{\bullet, j + 1}\)</span> achieving this maximum is the eigenvector corresponding to <span class="math inline">\(\sigma_{j + 1}^2\)</span>.</p>
<p>This reconstruction process terminates with an orthonormal set of <span class="math inline">\(d-\)</span>dimensional vectors, <span class="math inline">\((v_{\bullet, 1}, \ldots, v_{\bullet, r})\)</span>, that span subspace <span class="math inline">\(\mathcal{R}^{(r)}\)</span> that is spanned by the rows of <span class="math inline">\(X_{\bullet, \bullet}\)</span>.</p>
<p>Now let <span class="math inline">\(D\)</span> denote the <span class="math inline">\(r \times r\)</span> diagonal matrix <span class="math inline">\(diag(\sigma_1, \ldots, \sigma_r)\)</span>. From <a href="#eq-feature-variance-equals-norm2" class="quarto-xref">Equation&nbsp;<span>7.3</span></a> and <a href="#eq-next-row-projection-error-b" class="quarto-xref">Equation&nbsp;<span>7.10</span></a> we have</p>
<p><span id="eq-cov-trace-equals-eigen-sum"><span class="math display">\[
\begin{align}
  &amp;
    (n - 1) \;
    \sum_{k = 1}^d var(x_{\bullet, k})  \\
  &amp;=
    \sum_{k = 1}^d \; \lVert x_{\bullet, k} \rVert^2  \\
  &amp;=
    \mathrm{Tr}
    \left (
      X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
    \right )  \\
  &amp;=
    \sum_{\eta = 1}^r
    v_{\bullet, \eta}^\top \;
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \;
    v_{\bullet, \eta} \\
  &amp;=
    \sum_{\eta = 1}^r
    v_{\bullet, \eta}^\top \;
    ( \sigma_\eta^2 \; v_{\bullet, \eta} ) \\
  &amp;=
    \sum_{\eta = 1}^r \sigma_\eta^2 \\
  &amp;= \mathrm{Tr} \left ( D^2 \right )  \\ \\
  &amp;\text{where} \\ \\
  &amp; D = diag(\sigma_1, \ldots, \sigma_r)
\end{align}
\qquad(7.12)\]</span></span></p>
<p>That is, the sum of the eigenvalues <span class="math inline">\(\sigma_\eta^2\)</span> is equal to the sum of squared feature-norms, <span class="math inline">\(\lVert x_{\bullet, k} \rVert^2\)</span>.</p>
</section>
<section id="matrix-decompositions" class="level3" data-number="7.10.4">
<h3 data-number="7.10.4" class="anchored" data-anchor-id="matrix-decompositions"><span class="header-section-number">7.10.4</span> Matrix decompositions</h3>
<section id="covariance-matrix-polar-decomposition" class="level4" data-number="7.10.4.1">
<h4 data-number="7.10.4.1" class="anchored" data-anchor-id="covariance-matrix-polar-decomposition"><span class="header-section-number">7.10.4.1</span> Covariance Matrix: Polar Decomposition</h4>
<p>In the previous section we reconstructed rows of the feature matrix <span class="math inline">\(X_{\bullet, \bullet}\)</span> using a sequence of orthogonal projections <span class="math inline">\(v_{\bullet, \eta} \; v_{\bullet, \eta}^\top\)</span>. This development gave us a partial eigen-decomposition of the <span class="math inline">\(d \times d\)</span> matrix <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span>, the scaled feature covariance matrix. With <span class="math inline">\(r = rank(X_{\bullet, \bullet})\)</span>, and for <span class="math inline">\(\eta \in \{1, \ldots, r\}\)</span> the <span class="math inline">\(d-\)</span>dimensional vector <span class="math inline">\(v_{\bullet, \eta}\)</span> is an eigenvector of <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span>, having corresponding eigenvalue <span class="math inline">\(\sigma_\eta^2\)</span>, indexed in descending magnitude. In matrix notation we have:</p>
<p><span id="eq-cov-partial-eigen-decomp"><span class="math display">\[
\begin{align}
  &amp; \left (
    X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
  \right ) \;
    (v_{\bullet, 1}, \ldots, v_{\bullet, r}) \\
  &amp;=
  (v_{\bullet, 1}, \ldots, v_{\bullet, r}) \; D^2
\end{align}
\qquad(7.13)\]</span></span></p>
<p>Matrix <span class="math inline">\(X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}\)</span> is non-negative definite, which means that it has <span class="math inline">\(d\)</span> non-negative eigenvalues and corresponding eigenvectors. The first <span class="math inline">\(r\)</span> eigenvalues are positive. Arranged in descending order, they are the diagonal elements of <span class="math inline">\(D^2 = diag(\sigma_1^2, \ldots, \sigma_r^2)\)</span>. If <span class="math inline">\(r = d\)</span> the matrix is strictly positive-definite, and its complete eigen-decomposition is given by <a href="#eq-cov-partial-eigen-decomp" class="quarto-xref">Equation&nbsp;<span>7.13</span></a>.</p>
<p>Suppose now that <span class="math inline">\(r &lt; d\)</span>. Then any unit vector orthogonal to <span class="math inline">\(\mathcal{R}^{(r)}\)</span>, the <span class="math inline">\(d-\)</span>dimensional subspace spanned by <span class="math inline">\((v_{\bullet, 1}, \ldots, v_{\bullet, r})\)</span>, qualifies as an eigenvector (a “null” eigenvector, we’ll say) having an eigenvalue of zero. Therefore we can complement eigenvectors <span class="math inline">\((v_{\bullet, 1}, \ldots, v_{\bullet, r})\)</span> with an orthonormal set of null eigenvectors <span class="math inline">\((v_{\bullet, r + 1}, \ldots, v_{\bullet, d})\)</span>. The combined set of eigenvectors is a complete orthonormal basis for <span class="math inline">\(\mathbb{R}^d\)</span>.</p>
<p>We thus have two cases to consider: <span class="math inline">\(r &lt; d\)</span>; or <span class="math inline">\(r = d\)</span>. In either case we now have a complete orthonormal basis represented by the <span class="math inline">\(d \times d\)</span> matrix <span class="math inline">\(V = (v_{\bullet, 1}, \ldots, v_{\bullet, d})\)</span>. We delineate the two cases as follows.</p>
<p><span id="eq-cov-all-eigen-vectors-1"><span class="math display">\[
\begin{align}
  V_1 &amp;= (v_{\bullet, 1}, \ldots, v_{\bullet, r}) \\
  V_2 &amp;=
    \begin{cases}
      (v_{\bullet, r + 1}, \ldots, v_{\bullet, d}) &amp; \text{if } r &lt; d \\
      \emptyset &amp; \text{if } r = d
    \end{cases} \\
  V &amp;= (V_1, V_2)
\end{align}
\qquad(7.14)\]</span></span></p>
<p>We also record the full set of eigenvalues in the <span class="math inline">\(d \times d\)</span> diagonal matrix <span class="math inline">\(\tilde{D}^2\)</span> as follows.</p>
<p><span id="eq-cov-all-eigen-values-1"><span class="math display">\[
\begin{align}
  \tilde{D}^2 &amp;=
    \begin{cases}
      \begin{pmatrix}
        D^2 &amp; 0 \\
        0   &amp; 0
    \end{pmatrix}
    &amp; \text{if } r &lt; d \\
      D^2 &amp; \text{if } r = d
    \end{cases}
\end{align}
\qquad(7.15)\]</span></span></p>
<p>This enables us to re-express <a href="#eq-cov-partial-eigen-decomp" class="quarto-xref">Equation&nbsp;<span>7.13</span></a> as follows.</p>
<p><span id="eq-cov-full-eigen-decomp-1"><span class="math display">\[
\begin{align}
  \left (
    X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
  \right ) \;
    V
  &amp;=
    V \; \tilde{D}^2
\end{align}
\qquad(7.16)\]</span></span></p>
<p>Matrix <span class="math inline">\(V\)</span> is an orthonormal rotation of <span class="math inline">\(\mathbb{R}^d\)</span>, so that <span class="math inline">\(V^\top = V^{-1}\)</span>. Multiplying <a href="#eq-cov-full-eigen-decomp-1" class="quarto-xref">Equation&nbsp;<span>7.16</span></a> on the right by <span class="math inline">\(V^\top\)</span> we obtain:</p>
<p><span id="eq-cov-full-eigen-decomp-2"><span class="math display">\[
\begin{align}
  X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet}
  &amp;=
    V \; \tilde{D}^2 \; V^\top
\end{align}
\qquad(7.17)\]</span></span></p>
<p>This last equation can be re-expressed as an eigen-decomposition of the feature covariance matrix:</p>
<p><span id="eq-cov-full-eigen-decomp-3"><span class="math display">\[
\begin{align}
  &amp; cov(X_{\bullet, \bullet}) \\
  &amp;=
    \frac{1}{n-1} X_{\bullet, \bullet}^\top \; X_{\bullet, \bullet} \\
  &amp;= V \;
    \left (
      \frac{1}{n-1} \tilde{D}^2 \;
    \right )
    V^\top
\end{align}
\qquad(7.18)\]</span></span></p>
</section>
<section id="principal-components-of-the-feature-matrix" class="level4" data-number="7.10.4.2">
<h4 data-number="7.10.4.2" class="anchored" data-anchor-id="principal-components-of-the-feature-matrix"><span class="header-section-number">7.10.4.2</span> Principal Components of the Feature Matrix</h4>
<p>We now define <span class="math inline">\((c_{\bullet, 1}, \ldots, c_{\bullet, r})\)</span>, the <em>principal components</em> of <span class="math inline">\(X_{\bullet, \bullet}\)</span>, as the following respective linear combinations of the columns of <span class="math inline">\(X_{\bullet, \bullet}\)</span>.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<p><span id="eq-pc-defn-1"><span class="math display">\[
\begin{align}
  c_{\bullet, \eta}
  &amp;=
    X_{\bullet, \bullet} \; v_{\bullet, \eta}
    &amp; \text{ for } \eta \in \{ 1, \ldots, r \}
\end{align}
\qquad(7.19)\]</span></span></p>
<p>Note that distinct principal components are orthogonal, and the squared magnitude of <span class="math inline">\(c_{\bullet, \eta}\)</span> is <span class="math inline">\(\sigma_\eta^2\)</span>:</p>
<p><span id="eq-orthogonal-PCs"><span class="math display">\[
\begin{align}
  &amp;
    \left &lt;
      c_{\bullet, \kappa}
      , \;
      c_{\bullet, \eta}
    \right &gt; \\
  &amp;=
    \left &lt;
      X_{\bullet, \bullet} \;
      v_{\bullet, \kappa}
      , \;
      X_{\bullet, \bullet} \;
      v_{\bullet, \eta}
    \right &gt; \\
  &amp;=
    \left &lt;
      v_{\bullet, \kappa}
      , \;
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \;
      v_{\bullet, \eta}
    \right &gt; \\
  &amp;=
    \left &lt;
      v_{\bullet, \kappa}
      , \;
      \sigma_\eta^2 \;
      v_{\bullet, \eta}
    \right &gt; \\
  &amp;=
    \sigma_\eta^2 \;
    \left &lt;
      v_{\bullet, \kappa}
      , \;
      v_{\bullet, \eta}
    \right &gt; \\
  &amp;=
    \begin{cases}
      \sigma_\eta^2 &amp; \text{ if } \kappa = \eta \\
      0 &amp; \text{ if } \kappa \ne \eta
    \end{cases}
\end{align}
\qquad(7.20)\]</span></span></p>
</section>
<section id="svd-of-the-feature-matrix" class="level4" data-number="7.10.4.3">
<h4 data-number="7.10.4.3" class="anchored" data-anchor-id="svd-of-the-feature-matrix"><span class="header-section-number">7.10.4.3</span> SVD of the Feature Matrix</h4>
<p>Dividing <span class="math inline">\(c_{\bullet, \eta}\)</span> by its magnitude <span class="math inline">\(\sigma_\eta\)</span>, we obtain a unit vector <span class="math inline">\(u_{\bullet, \eta}\)</span> that represents the direction of <span class="math inline">\(c_{\bullet, \eta}\)</span>.</p>
<p><span id="eq-u-equals-pc-normalized"><span class="math display">\[
\begin{align}
  u_{\bullet, \eta}
  &amp;=
    \frac{ c _{\bullet, \eta} }{ \lVert c _{\bullet, \eta} \rVert } \\
  &amp;=
    \frac{ c _{\bullet, \eta} }{ \sigma_\eta }
    &amp; \text{ for } \eta \in \{ 1, \ldots, r \}
\end{align}
\qquad(7.21)\]</span></span></p>
<p>Since the principal components are pair-wise orthogonal, the unit vectors just defined make up an orthonormal set of <span class="math inline">\(n-\)</span>dimensional vectors. Note that</p>
<p><span id="eq-svd-1"><span class="math display">\[
\begin{align}
  u_{\bullet, \eta}^\top \; X_{\bullet, \bullet}
  &amp;=
    \frac{ 1 }{ \sigma_\eta } \;
    c_{\bullet, \eta}^\top \; X_{\bullet, \bullet} \\
  &amp;=
    \frac{ 1 }{ \sigma_\eta } \;
    \left (
      X_{\bullet, \bullet} \; v_{\bullet, \eta}
    \right )^\top   \;
    X_{\bullet, \bullet} \\
  &amp;=
    \frac{ 1 }{ \sigma_\eta } \;
    \left (
      v_{\bullet, \eta}^\top \; X_{\bullet, \bullet}^\top  
    \right )   \;
    X_{\bullet, \bullet} \\
  &amp;=
    \frac{ 1 }{ \sigma_\eta } \;
      v_{\bullet, \eta}^\top \;
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \\
  &amp;=
    \frac{ 1 }{ \sigma_\eta } \;
    \left (
      X_{\bullet, \bullet}^\top \;
      X_{\bullet, \bullet} \;
      v_{\bullet, \eta}
    \right )^\top \\
  &amp;=
    \frac{ 1 }{ \sigma_\eta } \;
    \left (
      \sigma_\eta^2 \;
      v_{\bullet, \eta}
    \right )^\top  \\
  &amp;=
    \sigma_\eta \;
    v_{\bullet, \eta}^\top
\end{align}
\qquad(7.22)\]</span></span></p>
<p>We now define <span class="math inline">\(U_1 = ( u_{\bullet, 1}, \ldots, u_{\bullet, r} )\)</span> to be the <span class="math inline">\(n \times r\)</span> matrix having these <span class="math inline">\(r\)</span> unit vectors as its columns. And we extend, if needed, this set of unit vectors to create an orthonormal basis for <span class="math inline">\(\mathbb{R}^n\)</span>. That is, if <span class="math inline">\(r &lt; n\)</span> then the vector space spanned by the columns of <span class="math inline">\(U_1\)</span> is a proper subspace of <span class="math inline">\(\mathbb{R}^n\)</span>. The orthogonal complement to this subspace has dimension <span class="math inline">\(n - r\)</span>, and thus admits an orthonormal basis, which we label as <span class="math inline">\(( u_{\bullet, r + 1}, \ldots, u_{\bullet, n} )\)</span>. And we define <span class="math inline">\(U_2\)</span> to be the matrix having these vectors as its columns. Finally, we define the <span class="math inline">\(n \times n\)</span> orthogonal matrix <span class="math inline">\(U = ( u_{\bullet, 1}, \ldots, u_{\bullet, n} )\)</span>.</p>
<p><span id="eq-all-left-eigen-vectors-1"><span class="math display">\[
\begin{align}
  U_1 &amp;= (u_{\bullet, 1}, \ldots, u_{\bullet, r}) \\
  U_2 &amp;=
    \begin{cases}
      (u_{\bullet, r + 1}, \ldots, u_{\bullet, n}) &amp; \text{if } r &lt; n \\
      \emptyset &amp; \text{if } r = n
    \end{cases} \\
  U &amp;= (U_1, U_2)
\end{align}
\qquad(7.23)\]</span></span></p>
<p>We can now re-express <a href="#eq-svd-1" class="quarto-xref">Equation&nbsp;<span>7.22</span></a> as follows.</p>
<p><span id="eq-svd-2"><span class="math display">\[
\begin{align}
  U^\top \; X_{\bullet, \bullet}
  &amp;=
    \Sigma \; V^\top
\end{align}
\qquad(7.24)\]</span></span></p>
<p>where <span class="math inline">\(\Sigma\)</span> is the following <span class="math inline">\(n \times d\)</span> rectangular diagonal matrix:</p>
<p><span id="eq-Sigma-defn"><span class="math display">\[
\begin{align}
  \Sigma &amp;=
    \begin{cases}
      \begin{pmatrix}
        \tilde{D} \\
        0
      \end{pmatrix} &amp; \text{ if } d &lt; n \\
      \tilde{D} &amp;  \text{ if } d = n \\
      \begin{pmatrix}
        \tilde{D} &amp; 0
      \end{pmatrix} &amp; \text{ if } d &gt; n
    \end{cases}
\end{align}
\qquad(7.25)\]</span></span></p>
<p>Then multiplying <a href="#eq-all-left-eigen-vectors-1" class="quarto-xref">Equation&nbsp;<span>7.23</span></a> on the left by matrix <span class="math inline">\(U\)</span> we obtain:</p>
<p><span id="eq-svd-3"><span class="math display">\[
\begin{align}
  X_{\bullet, \bullet}
  &amp;=
    U \; \Sigma \; V^\top
\end{align}
\qquad(7.26)\]</span></span></p>
<p>This factorization of the feature matrix <span class="math inline">\(X_{\bullet, \bullet}\)</span> is called a <em>singular value decomposition</em> (SVD).</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Bellman_1957_dynamic" class="csl-entry" role="listitem">
Bellman, Richard Ernest. 1957. <em>Dynamic Programming</em>. Princeton University Press.
</div>
<div id="ref-wine_quality_186" class="csl-entry" role="listitem">
Cortez, Paulo, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. 2009. <span>“Wine Quality.”</span> https://doi.org/<a href="https://doi.org/10.24432/C56S3T">https://doi.org/10.24432/C56S3T</a>.
</div>
<div id="ref-Cortez_2009_ModelingWP" class="csl-entry" role="listitem">
Cortez, P., Antonio Luíz Cerdeira, Fernando Almeida, Telmo Matos, and José Reis. 2009. <span>“Modeling Wine Preferences by Data Mining from Physicochemical Properties.”</span> <em>Decis. Support Syst.</em> 47: 547–53. <a href="https://api.semanticscholar.org/CorpusID:2996254">https://api.semanticscholar.org/CorpusID:2996254</a>.
</div>
<div id="ref-wiki_curse_dimensionality" class="csl-entry" role="listitem">
<span>“Curse of Dimensionality | Wikipedia.”</span> 2025. <em>Wikipedia</em>, November. <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">https://en.wikipedia.org/wiki/Curse_of_dimensionality</a>.
</div>
<div id="ref-Donoho_2000_High_Dimensional_Data_Analysis" class="csl-entry" role="listitem">
Donoho, David L. 2000. <span>“High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality,”</span> 1–32. <a href="https://www.researchgate.net/publication/220049061_High-Dimensional_Data_Analysis_The_Curses_and_Blessings_of_Dimensionality">https://www.researchgate.net/publication/220049061_High-Dimensional_Data_Analysis_The_Curses_and_Blessings_of_Dimensionality</a>.
</div>
<div id="ref-Koklu_Ozkan_2020_multiclass" class="csl-entry" role="listitem">
Koklu, Mehmet, and Ibrahim A Ozkan. 2020. <span>“Multiclass Classification of Dry Beans Using Computer Vision and Machine Learning Techniques.”</span> <em>Computers and Electronics in Agriculture</em> 174: 105507.
</div>
<div id="ref-Kuhn_Silge_tmwr" class="csl-entry" role="listitem">
Kuhn, Max, and Julia Silge. 2022. <em>Tidy Modeling with r</em>. O’Reilly Media. <a href="https://www.tmwr.org/">https://www.tmwr.org/</a>.
</div>
<div id="ref-McNeil_1977" class="csl-entry" role="listitem">
McNeil, Donald R. 1977. <em>Interactive Data Analysis: A Practical Primer</em>. New York, USA: John Wiley &amp; Sons.
</div>
<div id="ref-Ross_2000_Systematic" class="csl-entry" role="listitem">
Ross, Douglas T, Uwe Scherf, Michael B Eisen, Charles M Perou, Christian Rees, Paul Spellman, Vishwanath Iyer, et al. 2000. <span>“Systematic Variation in Gene Expression Patterns in Human Cancer Cell Lines.”</span> <em>Nature Genetics</em> 24: 227–35. <a href="https://doi.org/10.1038/73432">https://doi.org/10.1038/73432</a>.
</div>
</div>
</section>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>To develop and evaluate the classification models, the authors split the observations into three non-overlapping sets: training (<span class="math inline">\(n = 10206\)</span>, nearly 75%), testing <span class="math inline">\((n = 1703)\)</span>, and validation <span class="math inline">\((n = 1702)\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>For example, the features <code>area</code> and <code>convex_area</code> can differ in principle, but for the beans data the correlation is 0.99994.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The authors contributed the data (now archived) to the UC Irvine Machine Learning Repository. See <span class="citation" data-cites="wine_quality_186">Paulo Cortez et al. (<a href="references.html#ref-wine_quality_186" role="doc-biblioref">2009</a>)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The wines in this study are all from the Minho (northwest) region of Portugal. Medium in alcohol, it is appreciated for its freshness (especially in summer). At the time of writing the authors report that Minho wine accounts for 15% of total Portuguese wine production, of which some 10% is exported, mostly white wine.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The data are available from <code>R</code> package <code>ISLR2</code>. The vector of labels (cancer type per observation) can be accessed as <code>ISLR2::NCI60$labs</code>. The data can be accessed as <code>ISLR2::NCI60$data</code> in the form of a <span class="math inline">\(64 \times 6830\)</span> matrix with column names “1”, “2”, …, “6830” rather than gene identifiers. While this simplification is adequate for illustrating dimension reduction methods, readers requiring gene-level biological interpretation should consult the <code>rcellminer</code> and <code>rcellminerData</code> Bioconductor packages (Luna et al., 2016; Reinhold et al., 2019), which provide the same data with complete gene annotations and represent the current standard for programmatic access to NCI-60 molecular profiling data.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>The <code>ISLR2</code> package cites <span class="citation" data-cites="Ross_2000_Systematic">Ross et al. (<a href="references.html#ref-Ross_2000_Systematic" role="doc-biblioref">2000</a>)</span> as the source of <code>ISLR2::NCI60</code>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>See <span class="citation" data-cites="Bellman_1957_dynamic">Bellman (<a href="references.html#ref-Bellman_1957_dynamic" role="doc-biblioref">1957</a>)</span>, <span class="citation" data-cites="Donoho_2000_High_Dimensional_Data_Analysis">Donoho (<a href="references.html#ref-Donoho_2000_High_Dimensional_Data_Analysis" role="doc-biblioref">2000</a>)</span>, and <span class="citation" data-cites="wiki_curse_dimensionality"><span>“Curse of Dimensionality | Wikipedia”</span> (<a href="references.html#ref-wiki_curse_dimensionality" role="doc-biblioref">2025</a>)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Among the notations for the inner product (scalar product) of vectors <span class="math inline">\(x, y\)</span> belonging to the same Euclidean space are: (1) <span class="math inline">\(\left &lt; x, y \right&gt;\)</span>; and (2) <span class="math inline">\(x^\top \; y\)</span>. The latter conforms to the notation of matrix multiplication if <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are column vectors, and this is the tacit assumption without other information to the contrary. Ambiguity may occur when at least one of <span class="math inline">\(x, y\)</span> is a row or a column of some matrix. For example, if <span class="math inline">\(x\)</span> is a row vector and <span class="math inline">\(y\)</span> is a column vector, then the inner product of <span class="math inline">\(x, y\)</span> should be written either as <span class="math inline">\(\left &lt; x, y \right&gt;\)</span> or else as <span class="math inline">\(x \; y\)</span> according to matrix notation.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>We use the property of orthogonal projection <span class="math inline">\(P\)</span> that: <span class="math inline">\(\left &lt; x, P \; x \right &gt; = \left &lt; x, P^2 \; x \right &gt; = \left &lt; P \; x, P \; x \right &gt; = \lVert P \; x \rVert^2\)</span>.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Note that <span class="math inline">\(x_{i, \bullet} \in \mathbb{R}^d\)</span> is a row vector, namely the <span class="math inline">\(i^{th}\)</span> row of feature matrix <span class="math inline">\(X_{\bullet, \bullet}\)</span>. Therefore the inner product <span class="math inline">\(\left &lt; x_{i, \bullet}, \; P \; x_{i, \bullet} \right &gt;\)</span> is expressed as <span class="math inline">\(x_{i, \bullet} \; P \; x_{i, \bullet}^\top\)</span> in matrix multiplication notation.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Here we define “principal component” to mean <span class="math inline">\(X_{\bullet, \bullet} \; v_{\bullet, \eta}\)</span>, the linear combination of feature vectors. Other authors identify the coefficient vector <span class="math inline">\(v_{\bullet, \eta}\)</span> as the “principal component”.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/github\.com\/tthrall\/eda4ml\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./la-intro.html" class="pagination-link" aria-label="Linear Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Linear Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./text-analysis.html" class="pagination-link" aria-label="Text Analysis">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Text Analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/tthrall/eda4ml/edit/main/reduce-dim.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/tthrall/eda4ml/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>